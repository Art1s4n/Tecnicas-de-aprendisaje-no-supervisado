# -*- coding: utf-8 -*-
"""ReduccionDimesiones.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SnzOcQTjEydKQRNOcwQFV6uuf2Oozotj
"""

import pandas as pd

df = pd.read_csv('Pizza.csv')
df.head(5)

"""### Conteo de elementos basados en la marca"""

df["brand"].value_counts()

"""
### Trazado de todas las combinaciones de caracter√≠sticas con kde
"""

sns.pairplot(df.drop("id", axis=1), hue="brand", size=3, diag_kind="kde")

"""### Trazado de diagramas basados en la marca"""

g = sns.PairGrid(df,
                 y_vars=["brand"],
                 x_vars=list(df)[1:-1],
                 aspect=.75, size=3.5)
g.map(sns.violinplot, palette="pastel");

"""### Matriz de confusion"""

import numpy as np

corrmat = df.drop("id", axis=1).corr()
cols = corrmat.index
cm = np.corrcoef(df[cols].values.T)
sns.set(font_scale=1.25)
hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 15}, yticklabels=cols.values, xticklabels=cols.values)
plt.show()

from sklearn.model_selection import train_test_split
X = df.iloc[:, 1:8]
y = df.iloc[:, -1]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)

# before starting testing we standarise our data
from sklearn.preprocessing import StandardScaler

sc = StandardScaler()

sc.fit(X_train)

X_train_std = sc.transform(X_train)
X_test_std = sc.transform(X_test)

print(pd.DataFrame(X_train_std, columns=list(df)[1:-1]).head())

"""### Desarrollo del algoritmo PCA"""

from sklearn.preprocessing import StandardScaler
features = ['id', 'mois', 'prot', 'fat', 'ash', 'sodium', 'carb', 'cal']
#Estandarizando escalas
x = df.loc[:, features].values
y = df.loc[:,['brand']].values
x = StandardScaler().fit_transform(x)
print(x)

"""### Dividiendo en el numero de componentes"""

from sklearn.decomposition import PCA
pca = PCA(n_components=2)
principalComponents = pca.fit_transform(x)
principalDf = pd.DataFrame(data = principalComponents
             , columns = ['principal component 1', 'principal component 2'])
print(principalDf)

#Concatenando marcas al final del df
finalDf = pd.concat([principalDf, df[['brand']]], axis = 1)
print(finalDf)

"""### Graficando Componentes con sus respecticas etiquetas"""

import matplotlib.pyplot as plt
fig = plt.figure(figsize = (8,8))
ax = fig.add_subplot(1,1,1) 
ax.set_xlabel('Principal Component 1', fontsize = 15)
ax.set_ylabel('Principal Component 2', fontsize = 15)
ax.set_title('2 componentes PCA', fontsize = 20)
targets = ['A', 'D','G']
colors = ['r', 'g', 'b']
for target, color in zip(targets,colors):
    indicesToKeep = finalDf['brand'] == target
    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']
               , finalDf.loc[indicesToKeep, 'principal component 2']
               , c = color
               , s = 50)
ax.legend(targets)
ax.grid()

"""### Radio de Varianza"""

pca.explained_variance_ratio_

"""### Ejemplo con Isomap"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

from sklearn import manifold, datasets
from matplotlib.colors import ListedColormap

iris = datasets.load_iris()
isomap = manifold.Isomap(n_components=2)
new_dim = isomap.fit_transform(iris.data)

df = pd.DataFrame(new_dim, columns = ['principal component 1', 'principal component 2'])
df['brand'] = iris.target
df.head()

"""### Comparando Con otros metodos de Reduccion de Dimensiones con 3 componentes"""

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from matplotlib.ticker import NullFormatter
from sklearn.manifold import Isomap
from sklearn import datasets

from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.preprocessing import LabelEncoder
from matplotlib.ticker import NullFormatter
from sklearn import manifold
from mpl_toolkits.mplot3d import Axes3D

X = np.array(df[[c for c in df.columns if c != "brand" and c!='id']])
Y_df = df["brand"]
color = LabelEncoder().fit_transform(Y_df)

Axes3D

fig = plt.figure(figsize=(30, 8))
n_components=3
n_neighbors=5

#PCA

pca = PCA(n_components=n_components)
Y = pca.fit_transform(X)

ax = fig.add_subplot(131, projection='3d')
ax.scatter(Y[:, 0], Y[:, 1], Y[:, 2], c=color, cmap=plt.cm.Spectral)
ax.view_init(4, -72)
plt.title("PCA")

ax.axis('tight')
#MDS

mds = manifold.MDS(n_components, max_iter=100, n_init=1)
Y = mds.fit_transform(X)

ax = fig.add_subplot(132, projection='3d')
ax.scatter(Y[:, 0], Y[:, 1], Y[:, 2], c=color, cmap=plt.cm.Spectral)
ax.view_init(4, -72)
plt.title("MDS")
ax.axis('tight')

#Isomap
Y = manifold.Isomap(n_neighbors, n_components).fit_transform(X)

ax = fig.add_subplot(133, projection='3d')
ax.scatter(Y[:, 0], Y[:, 1], Y[:, 2], c=color, cmap=plt.cm.Spectral)
ax.view_init(4, -72)
plt.title("Isomap")

ax.axis('tight')
plt.show()